# Cluster LLaMA Distribuido

## Estado Actual del Proyecto

### âœ… Funcionalidades Comprobadas

1. **Nodos Windows**
   - Descubrimiento P2P entre nodos
   - ElecciÃ³n de lÃ­der automÃ¡tica
   - ConexiÃ³n WebSocket con el servidor central
   - Monitoreo de recursos (CPU, RAM, GPU)
   - DistribuciÃ³n del modelo
   - Procesamiento de inferencias
   - Manejo de errores y reconexiÃ³n
   - Monitoreo de VRAM y temperatura GPU

2. **Servidor Central**
   - API REST compatible con OpenAI
   - WebSocket para comunicaciÃ³n bidireccional
   - Dashboard en tiempo real
   - Balanceo de carga entre nodos
   - Manejo de desconexiones
   - Registro de estados y errores

3. **Dashboard**
   - VisualizaciÃ³n de nodos activos
   - Monitoreo de recursos en tiempo real
   - Estado de carga del modelo
   - DiferenciaciÃ³n visual entre tipos de nodos
   - ActualizaciÃ³n automÃ¡tica

### ðŸ”§ En Desarrollo

1. **Cliente Mac (MLX)**
   - IntegraciÃ³n con MLX para Apple Silicon
   - Monitoreo de Neural Engine
   - AdaptaciÃ³n del cliente para macOS
   - VisualizaciÃ³n en dashboard
   - MÃ©tricas especÃ­ficas de MLX

2. **Optimizaciones Pendientes**
   - Ajuste de velocidad de inferencia
   - MediciÃ³n de tokens por segundo
   - OptimizaciÃ³n de memoria
   - CachÃ© de resultados
   - CompresiÃ³n de comunicaciones

### ðŸ“‹ PrÃ³ximas Implementaciones

1. **Rendimiento**
   - Implementar mediciÃ³n de tokens/segundo
   - Optimizar velocidad de inferencia
   - Benchmark automÃ¡tico
   - Monitoreo de latencia
   - CachÃ© de resultados frecuentes

2. **DiseÃ±o y UX**
   - Mejorar interfaz del dashboard
   - GrÃ¡ficos de rendimiento histÃ³rico
   - Alertas y notificaciones
   - Temas claro/oscuro
   - Responsive design

3. **Funcionalidades**
   - GestiÃ³n de modelos mÃºltiples
   - Auto-escalado de nodos
   - Backup y recuperaciÃ³n
   - Logs centralizados
   - MÃ©tricas avanzadas

4. **Seguridad**
   - AutenticaciÃ³n de nodos
   - Cifrado de comunicaciones
   - Control de acceso
   - AuditorÃ­a de uso
   - ProtecciÃ³n contra ataques

## GuÃ­a de InstalaciÃ³n

### Windows
1. Instalar Node.js y Python
2. Configurar CUDA y drivers NVIDIA
3. Clonar el repositorio
4. Ejecutar `npm install` en cada directorio
5. Iniciar servidor: `cd server && node server-core.js`
6. Iniciar nodos: `cd client/windows-X && node index.js`

### Mac (En desarrollo)
1. Instalar Node.js y Python
2. Instalar MLX: `pip install mlx`
3. Clonar el repositorio
4. Ejecutar `npm install` en cada directorio
5. Dar permisos: `chmod +x start.sh`
6. Iniciar nodo: `./start.sh`

## Arquitectura

```
cluster/
â”œâ”€â”€ server/              # Servidor central
â”‚   â”œâ”€â”€ api/            # Endpoints REST
â”‚   â”œâ”€â”€ public/         # Dashboard
â”‚   â””â”€â”€ server-core.js  # NÃºcleo del servidor
â”œâ”€â”€ client/             # Clientes
â”‚   â”œâ”€â”€ windows-1/      # Nodo Windows 1
â”‚   â”œâ”€â”€ windows-2/      # Nodo Windows 2
â”‚   â””â”€â”€ mac-1/          # Nodo Mac (MLX)
â””â”€â”€ test/               # Scripts de prueba
```

## MÃ©tricas de Rendimiento (Por implementar)

- Tokens por segundo por nodo
- Latencia de respuesta
- Uso de memoria por modelo
- Eficiencia de distribuciÃ³n
- Tiempo de carga del modelo
- Tasa de error
- Disponibilidad del sistema

## ContribuciÃ³n

1. Fork del repositorio
2. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'AÃ±adir nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.
